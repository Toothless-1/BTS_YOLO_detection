{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10287488,"sourceType":"datasetVersion","datasetId":6366491}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport os\nimport PIL\nimport skimage\nfrom skimage import io\nimport numpy as np\nfrom PIL import Image\nimport shutil \nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms.functional as FT\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom torchinfo import summary\nimport copy\nimport datetime\nimport random\nimport traceback\nfrom IPython.display import display, clear_output\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nseed = 42\nimport cv2\nimport xml.etree.ElementTree as ET\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:02.310049Z","iopub.execute_input":"2024-12-26T14:51:02.310869Z","iopub.status.idle":"2024-12-26T14:51:07.716926Z","shell.execute_reply.started":"2024-12-26T14:51:02.310835Z","shell.execute_reply":"2024-12-26T14:51:07.716146Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from torchvision import models\nresnet50_model = models.resnet50(pretrained=True)\nresnet50_model.avgpool = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n#resnet18_model.avgpool = nn.Sequential()\nresnet50_model.fc = nn.Sequential()\nfor param in resnet50_model.parameters():\n    param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:07.718347Z","iopub.execute_input":"2024-12-26T14:51:07.718729Z","iopub.status.idle":"2024-12-26T14:51:08.831911Z","shell.execute_reply.started":"2024-12-26T14:51:07.718701Z","shell.execute_reply":"2024-12-26T14:51:08.831126Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 217MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"summary(resnet50_model, input_size=(16, 3, 448, 448))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:32.102970Z","iopub.execute_input":"2024-12-26T14:51:32.103361Z","iopub.status.idle":"2024-12-26T14:51:32.234315Z","shell.execute_reply.started":"2024-12-26T14:51:32.103326Z","shell.execute_reply":"2024-12-26T14:51:32.233537Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nResNet                                   [16, 100352]              --\n├─Conv2d: 1-1                            [16, 64, 224, 224]        9,408\n├─BatchNorm2d: 1-2                       [16, 64, 224, 224]        128\n├─ReLU: 1-3                              [16, 64, 224, 224]        --\n├─MaxPool2d: 1-4                         [16, 64, 112, 112]        --\n├─Sequential: 1-5                        [16, 256, 112, 112]       --\n│    └─Bottleneck: 2-1                   [16, 256, 112, 112]       --\n│    │    └─Conv2d: 3-1                  [16, 64, 112, 112]        4,096\n│    │    └─BatchNorm2d: 3-2             [16, 64, 112, 112]        128\n│    │    └─ReLU: 3-3                    [16, 64, 112, 112]        --\n│    │    └─Conv2d: 3-4                  [16, 64, 112, 112]        36,864\n│    │    └─BatchNorm2d: 3-5             [16, 64, 112, 112]        128\n│    │    └─ReLU: 3-6                    [16, 64, 112, 112]        --\n│    │    └─Conv2d: 3-7                  [16, 256, 112, 112]       16,384\n│    │    └─BatchNorm2d: 3-8             [16, 256, 112, 112]       512\n│    │    └─Sequential: 3-9              [16, 256, 112, 112]       16,896\n│    │    └─ReLU: 3-10                   [16, 256, 112, 112]       --\n│    └─Bottleneck: 2-2                   [16, 256, 112, 112]       --\n│    │    └─Conv2d: 3-11                 [16, 64, 112, 112]        16,384\n│    │    └─BatchNorm2d: 3-12            [16, 64, 112, 112]        128\n│    │    └─ReLU: 3-13                   [16, 64, 112, 112]        --\n│    │    └─Conv2d: 3-14                 [16, 64, 112, 112]        36,864\n│    │    └─BatchNorm2d: 3-15            [16, 64, 112, 112]        128\n│    │    └─ReLU: 3-16                   [16, 64, 112, 112]        --\n│    │    └─Conv2d: 3-17                 [16, 256, 112, 112]       16,384\n│    │    └─BatchNorm2d: 3-18            [16, 256, 112, 112]       512\n│    │    └─ReLU: 3-19                   [16, 256, 112, 112]       --\n│    └─Bottleneck: 2-3                   [16, 256, 112, 112]       --\n│    │    └─Conv2d: 3-20                 [16, 64, 112, 112]        16,384\n│    │    └─BatchNorm2d: 3-21            [16, 64, 112, 112]        128\n│    │    └─ReLU: 3-22                   [16, 64, 112, 112]        --\n│    │    └─Conv2d: 3-23                 [16, 64, 112, 112]        36,864\n│    │    └─BatchNorm2d: 3-24            [16, 64, 112, 112]        128\n│    │    └─ReLU: 3-25                   [16, 64, 112, 112]        --\n│    │    └─Conv2d: 3-26                 [16, 256, 112, 112]       16,384\n│    │    └─BatchNorm2d: 3-27            [16, 256, 112, 112]       512\n│    │    └─ReLU: 3-28                   [16, 256, 112, 112]       --\n├─Sequential: 1-6                        [16, 512, 56, 56]         --\n│    └─Bottleneck: 2-4                   [16, 512, 56, 56]         --\n│    │    └─Conv2d: 3-29                 [16, 128, 112, 112]       32,768\n│    │    └─BatchNorm2d: 3-30            [16, 128, 112, 112]       256\n│    │    └─ReLU: 3-31                   [16, 128, 112, 112]       --\n│    │    └─Conv2d: 3-32                 [16, 128, 56, 56]         147,456\n│    │    └─BatchNorm2d: 3-33            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-34                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-35                 [16, 512, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-36            [16, 512, 56, 56]         1,024\n│    │    └─Sequential: 3-37             [16, 512, 56, 56]         132,096\n│    │    └─ReLU: 3-38                   [16, 512, 56, 56]         --\n│    └─Bottleneck: 2-5                   [16, 512, 56, 56]         --\n│    │    └─Conv2d: 3-39                 [16, 128, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-40            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-41                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-42                 [16, 128, 56, 56]         147,456\n│    │    └─BatchNorm2d: 3-43            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-44                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-45                 [16, 512, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-46            [16, 512, 56, 56]         1,024\n│    │    └─ReLU: 3-47                   [16, 512, 56, 56]         --\n│    └─Bottleneck: 2-6                   [16, 512, 56, 56]         --\n│    │    └─Conv2d: 3-48                 [16, 128, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-49            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-50                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-51                 [16, 128, 56, 56]         147,456\n│    │    └─BatchNorm2d: 3-52            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-53                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-54                 [16, 512, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-55            [16, 512, 56, 56]         1,024\n│    │    └─ReLU: 3-56                   [16, 512, 56, 56]         --\n│    └─Bottleneck: 2-7                   [16, 512, 56, 56]         --\n│    │    └─Conv2d: 3-57                 [16, 128, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-58            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-59                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-60                 [16, 128, 56, 56]         147,456\n│    │    └─BatchNorm2d: 3-61            [16, 128, 56, 56]         256\n│    │    └─ReLU: 3-62                   [16, 128, 56, 56]         --\n│    │    └─Conv2d: 3-63                 [16, 512, 56, 56]         65,536\n│    │    └─BatchNorm2d: 3-64            [16, 512, 56, 56]         1,024\n│    │    └─ReLU: 3-65                   [16, 512, 56, 56]         --\n├─Sequential: 1-7                        [16, 1024, 28, 28]        --\n│    └─Bottleneck: 2-8                   [16, 1024, 28, 28]        --\n│    │    └─Conv2d: 3-66                 [16, 256, 56, 56]         131,072\n│    │    └─BatchNorm2d: 3-67            [16, 256, 56, 56]         512\n│    │    └─ReLU: 3-68                   [16, 256, 56, 56]         --\n│    │    └─Conv2d: 3-69                 [16, 256, 28, 28]         589,824\n│    │    └─BatchNorm2d: 3-70            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-71                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-72                 [16, 1024, 28, 28]        262,144\n│    │    └─BatchNorm2d: 3-73            [16, 1024, 28, 28]        2,048\n│    │    └─Sequential: 3-74             [16, 1024, 28, 28]        526,336\n│    │    └─ReLU: 3-75                   [16, 1024, 28, 28]        --\n│    └─Bottleneck: 2-9                   [16, 1024, 28, 28]        --\n│    │    └─Conv2d: 3-76                 [16, 256, 28, 28]         262,144\n│    │    └─BatchNorm2d: 3-77            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-78                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-79                 [16, 256, 28, 28]         589,824\n│    │    └─BatchNorm2d: 3-80            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-81                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-82                 [16, 1024, 28, 28]        262,144\n│    │    └─BatchNorm2d: 3-83            [16, 1024, 28, 28]        2,048\n│    │    └─ReLU: 3-84                   [16, 1024, 28, 28]        --\n│    └─Bottleneck: 2-10                  [16, 1024, 28, 28]        --\n│    │    └─Conv2d: 3-85                 [16, 256, 28, 28]         262,144\n│    │    └─BatchNorm2d: 3-86            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-87                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-88                 [16, 256, 28, 28]         589,824\n│    │    └─BatchNorm2d: 3-89            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-90                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-91                 [16, 1024, 28, 28]        262,144\n│    │    └─BatchNorm2d: 3-92            [16, 1024, 28, 28]        2,048\n│    │    └─ReLU: 3-93                   [16, 1024, 28, 28]        --\n│    └─Bottleneck: 2-11                  [16, 1024, 28, 28]        --\n│    │    └─Conv2d: 3-94                 [16, 256, 28, 28]         262,144\n│    │    └─BatchNorm2d: 3-95            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-96                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-97                 [16, 256, 28, 28]         589,824\n│    │    └─BatchNorm2d: 3-98            [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-99                   [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-100                [16, 1024, 28, 28]        262,144\n│    │    └─BatchNorm2d: 3-101           [16, 1024, 28, 28]        2,048\n│    │    └─ReLU: 3-102                  [16, 1024, 28, 28]        --\n│    └─Bottleneck: 2-12                  [16, 1024, 28, 28]        --\n│    │    └─Conv2d: 3-103                [16, 256, 28, 28]         262,144\n│    │    └─BatchNorm2d: 3-104           [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-105                  [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-106                [16, 256, 28, 28]         589,824\n│    │    └─BatchNorm2d: 3-107           [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-108                  [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-109                [16, 1024, 28, 28]        262,144\n│    │    └─BatchNorm2d: 3-110           [16, 1024, 28, 28]        2,048\n│    │    └─ReLU: 3-111                  [16, 1024, 28, 28]        --\n│    └─Bottleneck: 2-13                  [16, 1024, 28, 28]        --\n│    │    └─Conv2d: 3-112                [16, 256, 28, 28]         262,144\n│    │    └─BatchNorm2d: 3-113           [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-114                  [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-115                [16, 256, 28, 28]         589,824\n│    │    └─BatchNorm2d: 3-116           [16, 256, 28, 28]         512\n│    │    └─ReLU: 3-117                  [16, 256, 28, 28]         --\n│    │    └─Conv2d: 3-118                [16, 1024, 28, 28]        262,144\n│    │    └─BatchNorm2d: 3-119           [16, 1024, 28, 28]        2,048\n│    │    └─ReLU: 3-120                  [16, 1024, 28, 28]        --\n├─Sequential: 1-8                        [16, 2048, 14, 14]        --\n│    └─Bottleneck: 2-14                  [16, 2048, 14, 14]        --\n│    │    └─Conv2d: 3-121                [16, 512, 28, 28]         524,288\n│    │    └─BatchNorm2d: 3-122           [16, 512, 28, 28]         1,024\n│    │    └─ReLU: 3-123                  [16, 512, 28, 28]         --\n│    │    └─Conv2d: 3-124                [16, 512, 14, 14]         2,359,296\n│    │    └─BatchNorm2d: 3-125           [16, 512, 14, 14]         1,024\n│    │    └─ReLU: 3-126                  [16, 512, 14, 14]         --\n│    │    └─Conv2d: 3-127                [16, 2048, 14, 14]        1,048,576\n│    │    └─BatchNorm2d: 3-128           [16, 2048, 14, 14]        4,096\n│    │    └─Sequential: 3-129            [16, 2048, 14, 14]        2,101,248\n│    │    └─ReLU: 3-130                  [16, 2048, 14, 14]        --\n│    └─Bottleneck: 2-15                  [16, 2048, 14, 14]        --\n│    │    └─Conv2d: 3-131                [16, 512, 14, 14]         1,048,576\n│    │    └─BatchNorm2d: 3-132           [16, 512, 14, 14]         1,024\n│    │    └─ReLU: 3-133                  [16, 512, 14, 14]         --\n│    │    └─Conv2d: 3-134                [16, 512, 14, 14]         2,359,296\n│    │    └─BatchNorm2d: 3-135           [16, 512, 14, 14]         1,024\n│    │    └─ReLU: 3-136                  [16, 512, 14, 14]         --\n│    │    └─Conv2d: 3-137                [16, 2048, 14, 14]        1,048,576\n│    │    └─BatchNorm2d: 3-138           [16, 2048, 14, 14]        4,096\n│    │    └─ReLU: 3-139                  [16, 2048, 14, 14]        --\n│    └─Bottleneck: 2-16                  [16, 2048, 14, 14]        --\n│    │    └─Conv2d: 3-140                [16, 512, 14, 14]         1,048,576\n│    │    └─BatchNorm2d: 3-141           [16, 512, 14, 14]         1,024\n│    │    └─ReLU: 3-142                  [16, 512, 14, 14]         --\n│    │    └─Conv2d: 3-143                [16, 512, 14, 14]         2,359,296\n│    │    └─BatchNorm2d: 3-144           [16, 512, 14, 14]         1,024\n│    │    └─ReLU: 3-145                  [16, 512, 14, 14]         --\n│    │    └─Conv2d: 3-146                [16, 2048, 14, 14]        1,048,576\n│    │    └─BatchNorm2d: 3-147           [16, 2048, 14, 14]        4,096\n│    │    └─ReLU: 3-148                  [16, 2048, 14, 14]        --\n├─AvgPool2d: 1-9                         [16, 2048, 7, 7]          --\n├─Sequential: 1-10                       [16, 100352]              --\n==========================================================================================\nTotal params: 23,508,032\nTrainable params: 23,508,032\nNon-trainable params: 0\nTotal mult-adds (G): 261.58\n==========================================================================================\nInput size (MB): 38.54\nForward/backward pass size (MB): 11380.72\nParams size (MB): 94.03\nEstimated Total Size (MB): 11513.29\n=========================================================================================="},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"files_dir = '/kaggle/input/bts-members-detection/images'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:37.398854Z","iopub.execute_input":"2024-12-26T14:51:37.399263Z","iopub.status.idle":"2024-12-26T14:51:37.403291Z","shell.execute_reply.started":"2024-12-26T14:51:37.399229Z","shell.execute_reply":"2024-12-26T14:51:37.402383Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"temp1 = ['/'+image for image in sorted(os.listdir(files_dir))\n                        if (image[-4:]=='.png') and (image[:-4]+'.txt' in os.listdir(files_dir))\n         and os.path.getsize(files_dir+'/'+image[:-4]+'.txt') != 0]\ntemp2 = ['/'+annot for annot in sorted(os.listdir(files_dir))\n                        if (annot[-4:]=='.txt') and os.path.getsize(files_dir+'/'+annot) != 0]\n\nimages = pd.Series(temp1, name='images')\nimage_id = pd.Series(list(range(len(temp1))), name='id')\ntrain_img_df = pd.DataFrame(pd.concat([images, image_id], axis=1))\nimages = []\nimage_id = []\nfor i in range(len(temp1)):\n    with open(files_dir + temp2[i], 'r') as file:\n        for j in range(len(file.readlines())):\n            images.append(temp1[i])\n            image_id.append(i)\n        file.close()\nbboxes = []\nfor i in range(len(temp1)):\n    with open(files_dir + temp2[i], 'r') as file:\n        for line in file.readlines():\n            bboxes.append(list(map(float, line.split())))\n        file.close()\nimages = pd.Series(images, name='images')\nbboxes = pd.Series(bboxes, name='bboxes')\nimage_id = pd.Series(image_id, name='image_id')\nind = pd.Series(list(range(len(images))), name='id')\ndf = pd.concat([images, ind,image_id,bboxes], axis=1)\ntrain_df = pd.DataFrame(df)\narea = []\nfor i in range(train_df.shape[0]):\n    area.append(train_df.iloc[i,3][3]*train_df.iloc[i,3][4])\ntrain_df = pd.concat([train_df, pd.Series(area, name='area')],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:38.630904Z","iopub.execute_input":"2024-12-26T14:51:38.631756Z","iopub.status.idle":"2024-12-26T14:51:46.398344Z","shell.execute_reply.started":"2024-12-26T14:51:38.631719Z","shell.execute_reply":"2024-12-26T14:51:46.397620Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:46.400201Z","iopub.execute_input":"2024-12-26T14:51:46.400450Z","iopub.status.idle":"2024-12-26T14:51:46.422068Z","shell.execute_reply.started":"2024-12-26T14:51:46.400427Z","shell.execute_reply":"2024-12-26T14:51:46.421428Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"            images   id  image_id  \\\n0      /jhope0.png    0         0   \n1      /jhope1.png    1         1   \n2     /jhope10.png    2         2   \n3    /jhope100.png    3         3   \n4    /jhope101.png    4         4   \n..             ...  ...       ...   \n804      /v291.png  804       803   \n805      /v292.png  805       804   \n806      /v293.png  806       805   \n807      /v294.png  807       806   \n808      /v295.png  808       807   \n\n                                            bboxes      area  \n0    [0.0, 0.497253, 0.289855, 0.467033, 0.543478]  0.253822  \n1    [0.0, 0.477778, 0.391111, 0.848889, 0.782222]  0.664020  \n2             [0.0, 0.4, 0.393333, 0.408889, 0.44]  0.179911  \n3    [0.0, 0.555184, 0.446429, 0.622074, 0.892857]  0.555423  \n4     [0.0, 0.52901, 0.319767, 0.361775, 0.639535]  0.231368  \n..                                             ...       ...  \n804  [5.0, 0.553763, 0.279006, 0.218638, 0.292818]  0.064021  \n805  [5.0, 0.426667, 0.255556, 0.382222, 0.342222]  0.130805  \n806  [5.0, 0.591667, 0.494048, 0.456667, 0.714286]  0.326191  \n807   [5.0, 0.528796, 0.301136, 0.743455, 0.42803]  0.318221  \n808  [5.0, 0.507895, 0.390566, 0.952632, 0.615094]  0.585958  \n\n[809 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>images</th>\n      <th>id</th>\n      <th>image_id</th>\n      <th>bboxes</th>\n      <th>area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/jhope0.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0.0, 0.497253, 0.289855, 0.467033, 0.543478]</td>\n      <td>0.253822</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/jhope1.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>[0.0, 0.477778, 0.391111, 0.848889, 0.782222]</td>\n      <td>0.664020</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/jhope10.png</td>\n      <td>2</td>\n      <td>2</td>\n      <td>[0.0, 0.4, 0.393333, 0.408889, 0.44]</td>\n      <td>0.179911</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/jhope100.png</td>\n      <td>3</td>\n      <td>3</td>\n      <td>[0.0, 0.555184, 0.446429, 0.622074, 0.892857]</td>\n      <td>0.555423</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/jhope101.png</td>\n      <td>4</td>\n      <td>4</td>\n      <td>[0.0, 0.52901, 0.319767, 0.361775, 0.639535]</td>\n      <td>0.231368</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>804</th>\n      <td>/v291.png</td>\n      <td>804</td>\n      <td>803</td>\n      <td>[5.0, 0.553763, 0.279006, 0.218638, 0.292818]</td>\n      <td>0.064021</td>\n    </tr>\n    <tr>\n      <th>805</th>\n      <td>/v292.png</td>\n      <td>805</td>\n      <td>804</td>\n      <td>[5.0, 0.426667, 0.255556, 0.382222, 0.342222]</td>\n      <td>0.130805</td>\n    </tr>\n    <tr>\n      <th>806</th>\n      <td>/v293.png</td>\n      <td>806</td>\n      <td>805</td>\n      <td>[5.0, 0.591667, 0.494048, 0.456667, 0.714286]</td>\n      <td>0.326191</td>\n    </tr>\n    <tr>\n      <th>807</th>\n      <td>/v294.png</td>\n      <td>807</td>\n      <td>806</td>\n      <td>[5.0, 0.528796, 0.301136, 0.743455, 0.42803]</td>\n      <td>0.318221</td>\n    </tr>\n    <tr>\n      <th>808</th>\n      <td>/v295.png</td>\n      <td>808</td>\n      <td>807</td>\n      <td>[5.0, 0.507895, 0.390566, 0.952632, 0.615094]</td>\n      <td>0.585958</td>\n    </tr>\n  </tbody>\n</table>\n<p>809 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:46.422936Z","iopub.execute_input":"2024-12-26T14:51:46.423215Z","iopub.status.idle":"2024-12-26T14:51:46.553115Z","shell.execute_reply.started":"2024-12-26T14:51:46.423192Z","shell.execute_reply":"2024-12-26T14:51:46.552490Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train, test = train_test_split(df, test_size = 0.2, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:46.554429Z","iopub.execute_input":"2024-12-26T14:51:46.554686Z","iopub.status.idle":"2024-12-26T14:51:46.560976Z","shell.execute_reply.started":"2024-12-26T14:51:46.554663Z","shell.execute_reply":"2024-12-26T14:51:46.560162Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"img_transforms  = transforms.Compose([\n    transforms.Resize((448, 448)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[-0.0932, -0.0971, -0.1260], std=[0.5091, 0.4912, 0.4931])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:49.492520Z","iopub.execute_input":"2024-12-26T14:51:49.492843Z","iopub.status.idle":"2024-12-26T14:51:49.497521Z","shell.execute_reply.started":"2024-12-26T14:51:49.492817Z","shell.execute_reply":"2024-12-26T14:51:49.496637Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!mkdir train test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:52.947641Z","iopub.execute_input":"2024-12-26T14:51:52.948372Z","iopub.status.idle":"2024-12-26T14:51:53.982039Z","shell.execute_reply.started":"2024-12-26T14:51:52.948335Z","shell.execute_reply":"2024-12-26T14:51:53.980847Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!mkdir train/jhope train/jin train/jimin train/jungkook train/suga train/rm train/v","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:54.310677Z","iopub.execute_input":"2024-12-26T14:51:54.311591Z","iopub.status.idle":"2024-12-26T14:51:55.315938Z","shell.execute_reply.started":"2024-12-26T14:51:54.311553Z","shell.execute_reply":"2024-12-26T14:51:55.314509Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"!mkdir test/jhope test/jin test/jimin test/jungkook test/suga test/rm test/v","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:56.873429Z","iopub.execute_input":"2024-12-26T14:51:56.873852Z","iopub.status.idle":"2024-12-26T14:51:57.883275Z","shell.execute_reply.started":"2024-12-26T14:51:56.873818Z","shell.execute_reply":"2024-12-26T14:51:57.882051Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"names = sorted(['jhope', 'jimin', 'jin', 'suga', 'jungkook', 'rm', 'v'])\nclass_names = dict((i, names[i]) for i in range(7))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:51:58.271992Z","iopub.execute_input":"2024-12-26T14:51:58.272328Z","iopub.status.idle":"2024-12-26T14:51:58.277344Z","shell.execute_reply.started":"2024-12-26T14:51:58.272295Z","shell.execute_reply":"2024-12-26T14:51:58.276500Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"for class_name in class_names:\n    for i in range(train.shape[0]):\n        temp = train.iloc[i,0].split('.')[0][1:]\n        flags = list(map(str.isalpha, list(temp)))\n        temp_str = temp[:flags.index(False)]\n        if temp_str == class_names.get(class_name):\n            shutil.copy(files_dir+train.iloc[i,0], \\\n                        '/kaggle/working/train'+'/'+class_names.get(class_name)+train.iloc[i,0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:00.736567Z","iopub.execute_input":"2024-12-26T14:52:00.737414Z","iopub.status.idle":"2024-12-26T14:52:06.820659Z","shell.execute_reply.started":"2024-12-26T14:52:00.737376Z","shell.execute_reply":"2024-12-26T14:52:06.819687Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!ls train/v","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:06.822365Z","iopub.execute_input":"2024-12-26T14:52:06.823040Z","iopub.status.idle":"2024-12-26T14:52:07.831162Z","shell.execute_reply.started":"2024-12-26T14:52:06.822998Z","shell.execute_reply":"2024-12-26T14:52:07.830021Z"}},"outputs":[{"name":"stdout","text":"v0.png\t  v11.png   v15.png   v179.png\tv196.png  v208.png  v27.png   v286.png\nv10.png   v110.png  v16.png   v18.png\tv197.png  v209.png  v270.png  v287.png\nv101.png  v112.png  v169.png  v180.png\tv198.png  v21.png   v272.png  v288.png\nv102.png  v113.png  v170.png  v183.png\tv199.png  v212.png  v273.png  v289.png\nv103.png  v114.png  v172.png  v185.png\tv2.png\t  v213.png  v274.png  v293.png\nv104.png  v117.png  v173.png  v187.png\tv20.png   v218.png  v275.png  v294.png\nv105.png  v118.png  v174.png  v19.png\tv200.png  v22.png   v278.png  v295.png\nv106.png  v119.png  v175.png  v192.png\tv201.png  v23.png   v280.png\nv107.png  v12.png   v176.png  v193.png\tv204.png  v25.png   v281.png\nv109.png  v14.png   v177.png  v194.png\tv206.png  v26.png   v283.png\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"for class_name in class_names:\n    for i in range(test.shape[0]):\n        temp = test.iloc[i,0].split('.')[0][1:]\n        flags = list(map(str.isalpha, list(temp)))\n        temp_str = temp[:flags.index(False)]\n        if temp_str == class_names.get(class_name):\n            shutil.copy(files_dir+test.iloc[i,0], \\\n                        '/kaggle/working/test'+'/'+class_names.get(class_name)+test.iloc[i,0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:12.084859Z","iopub.execute_input":"2024-12-26T14:52:12.085627Z","iopub.status.idle":"2024-12-26T14:52:13.620001Z","shell.execute_reply.started":"2024-12-26T14:52:12.085587Z","shell.execute_reply":"2024-12-26T14:52:13.619053Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!ls test/suga","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:14.599761Z","iopub.execute_input":"2024-12-26T14:52:14.600052Z","iopub.status.idle":"2024-12-26T14:52:15.602566Z","shell.execute_reply.started":"2024-12-26T14:52:14.600026Z","shell.execute_reply":"2024-12-26T14:52:15.601437Z"}},"outputs":[{"name":"stdout","text":"suga112.png  suga181.png  suga25.png  suga276.png  suga316.png\tsuga381.png\nsuga119.png  suga20.png   suga26.png  suga277.png  suga371.png\nsuga14.png   suga211.png  suga27.png  suga309.png  suga378.png\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_data = ImageFolder(root='/kaggle/working/train', transform=img_transforms)\nvalidation_data = ImageFolder(root='/kaggle/working/test', transform=img_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:19.263264Z","iopub.execute_input":"2024-12-26T14:52:19.263639Z","iopub.status.idle":"2024-12-26T14:52:19.272743Z","shell.execute_reply.started":"2024-12-26T14:52:19.263604Z","shell.execute_reply":"2024-12-26T14:52:19.272100Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset=train_data, batch_size=10, shuffle=True, num_workers=2)\nvalidation_dataloader = DataLoader(dataset=validation_data, batch_size=4, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:34.643083Z","iopub.execute_input":"2024-12-26T14:52:34.643446Z","iopub.status.idle":"2024-12-26T14:52:34.648826Z","shell.execute_reply.started":"2024-12-26T14:52:34.643416Z","shell.execute_reply":"2024-12-26T14:52:34.647794Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def copy_data_to_device(data, device):\n    if torch.is_tensor(data):\n        return data.to(device)\n    elif isinstance(data, (list, tuple)):\n        return [copy_data_to_device(elem, device) for elem in data]\n    raise ValueError('Недопустимый тип данных {}'.format(type(data)))\n\n\ndef print_grad_stats(model):\n    mean = 0\n    std = 0\n    norm = 1e-5\n    for param in model.parameters():\n        grad = getattr(param, 'grad', None)\n        if grad is not None:\n            mean += grad.data.abs().mean()\n            std += grad.data.std()\n            norm += 1\n    mean /= norm\n    std /= norm\n    print(f'Mean grad {mean}, std {std}, n {norm}')\n\n\ndef train_eval_loop(model, train_dataset, val_dataset, criterion,\n                    lr=1e-4, epoch_n=10, batch_size=16,\n                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n                    max_batches_per_epoch_train=10000,\n                    max_batches_per_epoch_val=1000,\n                    data_loader_ctor=DataLoader,\n                    optimizer_ctor=None,\n                    lr_scheduler_ctor=None,\n                    shuffle_train=True,\n                    dataloader_workers_n=0,\n                    step_size=10,\n                    plot=False):\n    \"\"\"\n    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n    :param model: torch.nn.Module - обучаемая модель\n    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n    :param criterion: функция потерь для настройки модели\n    :param lr: скорость обучения\n    :param epoch_n: максимальное количество эпох\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n        отсутствие улучшения модели, чтобы обучение продолжалось.\n    :param l2_reg_alpha: коэффициент L2-регуляризации\n    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n        (по умолчанию torch.utils.data.DataLoader)\n    :return: кортеж из двух элементов:\n        - среднее значение функции потерь на валидации на лучшей эпохе\n        - лучшая модель\n    \"\"\"\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    device = torch.device(device)\n    model.to(device)\n\n    if optimizer_ctor is None:\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n    else:\n        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n\n    if lr_scheduler_ctor is not None:\n        lr_scheduler = lr_scheduler_ctor(optimizer, step_size)\n    else:\n        lr_scheduler = None\n\n    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n                                        num_workers=dataloader_workers_n)\n    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n                                      num_workers=dataloader_workers_n)\n\n    best_val_loss = float('inf')\n    best_epoch_i = 0\n    best_model = copy.deepcopy(model)\n\n# Dynamic plot\n    if plot:\n        plot_epoch_data = []\n        plot_train_loss = []\n        plot_val_loss = []\n\n        fig, ax = plt.subplots()\n        line_train, = ax.plot([], [], 'r-')\n        line_val, = ax.plot([], [], 'b-')\n        ax.legend(['train', 'val'])\n        ax.set_xlim(0, epoch_n)\n\n        def add_point(epoch_i, train_loss, val_loss):\n            max_loss = max(ax.viewLim.y1 / 1.1, train_loss, val_loss)\n            ax.set_ylim(0, max_loss * 1.1)\n            \n            plot_epoch_data.append(epoch_i)\n            plot_train_loss.append(train_loss)\n            plot_val_loss.append(val_loss)\n            line_train.set_data(plot_epoch_data, plot_train_loss)\n            line_val.set_data(plot_epoch_data, plot_val_loss)\n            clear_output(wait=True)\n            display(fig)\n\n\n    for epoch_i in range(epoch_n):\n        try:\n            epoch_start = datetime.datetime.now()\n            \n\n            print('Эпоха {}'.format(epoch_i))\n\n            model.train()\n            mean_train_loss = 0\n            train_batches_n = 0\n            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n                if batch_i > max_batches_per_epoch_train:\n                    break\n\n                batch_x = copy_data_to_device(batch_x, device)\n                batch_y = copy_data_to_device(batch_y, device)\n\n                pred = model(batch_x)\n                loss = criterion(pred, batch_y)\n\n                model.zero_grad()\n                loss.backward()\n\n                optimizer.step()\n\n                mean_train_loss += float(loss)\n                train_batches_n += 1\n\n            mean_train_loss /= train_batches_n\n\n            print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n            print('Среднее значение функции потерь на обучении', mean_train_loss)\n\n\n\n            model.eval()\n            mean_val_loss = 0\n            val_batches_n = 0\n\n            with torch.no_grad():\n                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n                    if batch_i > max_batches_per_epoch_val:\n                        break\n\n                    batch_x = copy_data_to_device(batch_x, device)\n                    batch_y = copy_data_to_device(batch_y, device)\n\n                    pred = model(batch_x)\n                    loss = criterion(pred, batch_y)\n\n                    mean_val_loss += float(loss)\n                    val_batches_n += 1\n\n            mean_val_loss /= val_batches_n\n\n            if plot:\n                add_point(epoch_i, mean_train_loss, mean_val_loss)\n            else:\n                pass\n            \n            print('Среднее значение функции потерь на валидации', mean_val_loss)\n\n            if mean_val_loss < best_val_loss:\n                best_epoch_i = epoch_i\n                best_val_loss = mean_val_loss\n                best_model = copy.deepcopy(model)\n                print('Новая лучшая модель! На эпохе {}'.format(epoch_i))\n            elif epoch_i - best_epoch_i > early_stopping_patience:\n                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n                    early_stopping_patience))\n                break\n\n            if lr_scheduler is not None:\n                lr_scheduler.step(mean_val_loss)\n\n            print()\n        except KeyboardInterrupt:\n            print('Досрочно остановлено пользователем')\n            break\n        except Exception as ex:\n            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n            break\n        finally:\n            if plot:\n                plt.close(fig)\n\n    return best_val_loss, best_model\n\n\ndef predict_with_model(model, dataset, device=None, batch_size=32, num_workers=0, return_labels=False):\n    \"\"\"\n    :param model: torch.nn.Module - обученная модель\n    :param dataset: torch.utils.data.Dataset - данные для применения модели\n    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n    :return: numpy.array размерности len(dataset) x *\n    \"\"\"\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    results_by_batch = []\n\n    device = torch.device(device)\n    model.to(device)\n    model.eval()\n\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    labels = []\n    with torch.no_grad():\n        import tqdm\n        for batch_x, batch_y in tqdm.tqdm(dataloader, total=len(dataset)/batch_size):\n            batch_x = copy_data_to_device(batch_x, device)\n\n            if return_labels:\n                labels.append(batch_y.numpy())\n\n            batch_pred = model(batch_x)\n            results_by_batch.append(batch_pred.detach().cpu().numpy())\n\n    if return_labels:\n        return np.concatenate(results_by_batch, 0), np.concatenate(labels, 0)\n    else:\n        return np.concatenate(results_by_batch, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:37.885456Z","iopub.execute_input":"2024-12-26T14:52:37.885816Z","iopub.status.idle":"2024-12-26T14:52:37.908253Z","shell.execute_reply.started":"2024-12-26T14:52:37.885788Z","shell.execute_reply":"2024-12-26T14:52:37.907393Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:46.263849Z","iopub.execute_input":"2024-12-26T14:52:46.264805Z","iopub.status.idle":"2024-12-26T14:52:46.269119Z","shell.execute_reply.started":"2024-12-26T14:52:46.264768Z","shell.execute_reply":"2024-12-26T14:52:46.268084Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"best_loss, best_model = train_eval_loop(model=resnet50_model, \n                train_dataset=train_data, \n                val_dataset=validation_data, \n                criterion=nn.CrossEntropyLoss(),\n                lr=1e-3, \n                epoch_n=100, \n                batch_size=4,\n                device=device, \n                early_stopping_patience=20, \n                l2_reg_alpha=0.2,\n                max_batches_per_epoch_train=10000,\n                max_batches_per_epoch_val=1000,\n                data_loader_ctor=DataLoader,\n                optimizer_ctor=torch.optim.Adam,\n                lr_scheduler_ctor=torch.optim.lr_scheduler.StepLR,\n                step_size = 5,\n                shuffle_train=True,\n                dataloader_workers_n=2,\n                plot=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:52:53.970681Z","iopub.execute_input":"2024-12-26T14:52:53.971381Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Среднее значение функции потерь на валидации 2.230405528370927\nНовая лучшая модель! На эпохе 6\n\nЭпоха 7\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"predicted_labels = []\nactual_labels = []\n\nresnet50_model.eval()  # Set the model to evaluation mode\nwith torch.inference_mode():  # Ensure no gradients are computed\n    for images, labels in validation_dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = resnet50_model(images)\n        _, predicted = torch.max(outputs, 1)\n        predicted_labels.extend(predicted.cpu().numpy())\n        actual_labels.extend(labels.cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:48:43.168367Z","iopub.execute_input":"2024-12-26T14:48:43.168844Z","iopub.status.idle":"2024-12-26T14:48:44.659684Z","shell.execute_reply.started":"2024-12-26T14:48:43.168814Z","shell.execute_reply":"2024-12-26T14:48:44.658514Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, \\\nclassification_report, confusion_matrix\n\n# Вычисление тестовых метрик\naccuracy = accuracy_score(actual_labels, predicted_labels)\nprecision = precision_score(actual_labels, predicted_labels, average='weighted', zero_division=0)\nrecall = recall_score(actual_labels, predicted_labels, average='weighted', zero_division=0)\nf1 = f1_score(actual_labels, predicted_labels, average='weighted', zero_division=0)\n\n# Принт метрик\nprint(f\"Model Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Model Precision: {precision * 100:.2f}%\")\nprint(f\"Model Recall: {recall * 100:.2f}%\")\nprint(f\"Model F1 Score: {f1 * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:48:44.661021Z","iopub.execute_input":"2024-12-26T14:48:44.661350Z","iopub.status.idle":"2024-12-26T14:48:44.677294Z","shell.execute_reply.started":"2024-12-26T14:48:44.661297Z","shell.execute_reply":"2024-12-26T14:48:44.676381Z"}},"outputs":[{"name":"stdout","text":"Model Accuracy: 20.37%\nModel Precision: 21.19%\nModel Recall: 20.37%\nModel F1 Score: 19.71%\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"cm = confusion_matrix(actual_labels, predicted_labels)\nclass_names = validation_dataloader.dataset.classes\n\nplt.figure(figsize=(10, 10))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('Actual Labels')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T14:48:44.678883Z","iopub.execute_input":"2024-12-26T14:48:44.679154Z","iopub.status.idle":"2024-12-26T14:48:45.057165Z","shell.execute_reply.started":"2024-12-26T14:48:44.679124Z","shell.execute_reply":"2024-12-26T14:48:45.056354Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x1000 with 2 Axes>","image/png":"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"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class YoloV1(nn.Module):\n    def __init__(self, in_channels=7, out_conv_channels=2048, **kwargs):\n        super(YoloV1, self).__init__()\n        self.in_channels = in_channels\n        self.model_channels = out_conv_channels\n        self.darknet = resnet50_model\n        self.fcs = self._create_fcs(**kwargs)\n        \n    def forward(self, x):\n        x = self.darknet(x)\n        return self.fcs(torch.flatten(x, start_dim=1))\n    \n    def _create_fcs(self, split_size, num_boxes, num_classes):\n        \"\"\"\n        В изначальной статье используется nn.Linear(1024 * S * S, 4096), но не 496. \n        Также у последнего слоя будет изменена размерность до (S, S, 13) где C+B*5 = 13\n        \"\"\"\n        S, B, C = split_size, num_boxes, num_classes\n        return nn.Sequential(\n            nn.Flatten(), \n            nn.Linear(self.model_channels * S * S, 496), \n            nn.Dropout(0.0), \n            nn.LeakyReLU(0.1), \n            nn.Linear(496, S * S * (C + B * 5))\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:25.749761Z","iopub.execute_input":"2024-12-24T17:57:25.750021Z","iopub.status.idle":"2024-12-24T17:57:25.756457Z","shell.execute_reply.started":"2024-12-24T17:57:25.749997Z","shell.execute_reply":"2024-12-24T17:57:25.755627Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"Этот код на Python вычисляет пересечение над объединением (Intersection over Union, IoU) для пар предсказанных и истинных ограничивающих рамок. IoU — это метрика, которая часто используется в задачах компьютерного зрения для оценки качества предсказанных ограничивающих рамок. Вот как работает этот код:\n\n1. Параметры функции:\n\n   • boxes_preds — тензор с предсказанными ограничивающими рамками размером (BATCH_SIZE, 4).\n\n   • boxes_labels — тензор с истинными ограничивающими рамками размером (BATCH_SIZE, 4).\n\n   • box_format — формат представления рамок: 'midpoint' (центр и размеры) или 'corners' (координаты углов).\n\n2. Преобразование формата рамок:\n\n   • Если формат 'midpoint', рамки преобразуются из формата (x, y, w, h) в (x1, y1, x2, y2).\n\n   • Если формат 'corners', рамки уже в нужном формате (x1, y1, x2, y2).\n\n3. Вычисление координат пересечения:\n\n   • Используется функция torch.max для вычисления верхних левых углов пересечения.\n\n   • Используется функция torch.min для вычисления нижних правых углов пересечения.\n\n4. Вычисление площади пересечения:\n\n   • Площадь пересечения вычисляется как произведение высоты и ширины пересекающейся области. Для случая, когда рамки не пересекаются, используется .clamp(0), чтобы избежать отрицательных значений.\n\n5. Вычисление площадей отдельных рамок:\n\n   • Площади предсказанных и истинных рамок вычисляются на основе их координат.\n\n6. Вычисление IoU:\n\n   • IoU вычисляется как отношение площади пересечения к объединенной площади двух рамок (площадь первой рамки + площадь второй рамки - площадь пересечения). Небольшая константа 1e-6 добавляется к знаменателю для предотвращения деления на ноль.\n\nЭтот код полезен для оценки качества алгоритмов обнаружения объектов, так как позволяет количественно оценить, насколько хорошо предсказанные ограничивающие рамки соответствуют истинным объектам на изображении.\n","metadata":{}},{"cell_type":"code","source":"def intersection_over_union(boxes_preds, boxes_labels, box_format='midpoint'):\n    if box_format == 'midpoint':\n        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n        \n    if box_format == 'corners':\n        box1_x1 = boxes_preds[..., 0:1]\n        box1_y1 = boxes_preds[..., 1:2]\n        box1_x2 = boxes_preds[..., 2:3]\n        box1_y2 = boxes_preds[..., 3:4] \n        box2_x1 = boxes_labels[..., 0:1]\n        box2_y1 = boxes_labels[..., 1:2]\n        box2_x2 = boxes_labels[..., 2:3]\n        box2_y2 = boxes_labels[..., 3:4]\n    \n    x1 = torch.max(box1_x1, box2_x1)\n    y1 = torch.max(box1_y1, box2_y1)\n    x2 = torch.min(box1_x2, box2_x2)\n    y2 = torch.min(box1_y2, box2_y2)\n    \n    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n    \n    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n    \n    return intersection / (box1_area + box2_area - intersection + 1e-6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:25.758449Z","iopub.execute_input":"2024-12-24T17:57:25.758825Z","iopub.status.idle":"2024-12-24T17:57:25.770705Z","shell.execute_reply.started":"2024-12-24T17:57:25.758800Z","shell.execute_reply":"2024-12-24T17:57:25.770045Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n    \"\"\"\n    Выполняет подавление немаксимумов (Non Max Suppression) для заданных ограничивающих рамок.\n    Параметры:\n        bboxes (list): список списков, содержащих все ограничивающие рамки, \n        каждая из которых представлена как [class_pred, prob_score, x1, y1, x2, y2]\n        iou_threshold (float): порог, при котором предсказанная рамка считается корректной\n        threshold (float): порог для удаления предсказанных рамок (независимо от IoU)\n        box_format (str): \"midpoint\" или \"corners\", используемый для указания формата рамок\n    Возвращает:\n        list: ограничивающие рамки после выполнения NMS с заданным порогом IoU\n    \"\"\"\n    assert type(bboxes) == list\n\n    bboxes = [box for box in bboxes if box[1] > threshold]\n    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n    bboxes_after_nms = []\n\n    while bboxes:\n        chosen_box = bboxes.pop(0)\n\n        bboxes = [\n            box\n            for box in bboxes\n            if box[0] != chosen_box[0]\n            or intersection_over_union(\n                torch.tensor(chosen_box[2:]),\n                torch.tensor(box[2:]),\n                box_format=box_format,\n            )\n            < iou_threshold\n        ]\n\n        bboxes_after_nms.append(chosen_box)\n\n    return bboxes_after_nms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:25.771578Z","iopub.execute_input":"2024-12-24T17:57:25.771800Z","iopub.status.idle":"2024-12-24T17:57:25.787506Z","shell.execute_reply.started":"2024-12-24T17:57:25.771778Z","shell.execute_reply":"2024-12-24T17:57:25.786775Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def mean_average_precision(\n    pred_boxes, true_boxes, iou_threshold=0.5, box_format=\"midpoint\", num_classes=7\n):\n    \"\"\"\n    Вычисляет среднюю точность (mean average precision).\n    Параметры:\n        pred_boxes (list): список списков, содержащих все ограничивающие рамки, \n        каждая из которых представлена как [train_idx, class_prediction, prob_score, x1, y1, x2, y2]\n        true_boxes (list): аналогично pred_boxes, но для всех правильных\n        iou_threshold (float): порог, при котором предсказанная рамка считается корректной\n        box_format (str): \"midpoint\" или \"corners\", используемый для указания формата рамок\n        num_classes (int): количество классов\n    Возвращает:\n        float: значение mAP для всех классов при заданном пороге IoU\n    \"\"\"\n\n    # список для хранения всех AP для соответствующих классов\n    average_precisions = []\n\n    # используется для численной стабильности позже\n    epsilon = 1e-6\n    for c in range(num_classes):\n        detections = []\n        ground_truths = []\n\n        # Проходим через все предсказания и цели,\n        # и добавляем только те, которые принадлежат\n        # текущему классу c\n        for detection in pred_boxes:\n            if detection[1] == c:\n                detections.append(detection)\n\n        for true_box in true_boxes:\n            if true_box[1] == c:\n                ground_truths.append(true_box)\n\n        # находим количество рамок для каждого обучающего примера\n        # Counter здесь находит, сколько истинных рамок мы получаем\n        # для каждого обучающего примера. Например, если у img 0 их 3,\n        # а у img 1 их 5, то мы получим словарь с:\n        # amount_bboxes = {0:3, 1:5}\n        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n\n        # Затем мы проходим через каждый ключ и значение в этом словаре\n        # и преобразуем в следующее (относительно того же примера):\n        # amount_bboxes = {0:torch.tensor[0,0,0], 1:torch.tensor[0,0,0,0,0]}\n        for key, val in amount_bboxes.items():\n            amount_bboxes[key] = torch.zeros(val)\n\n        # сортируем по вероятностям рамок, которые находятся в индексе 2\n        detections.sort(key=lambda x: x[2], reverse=True)\n        TP = torch.zeros((len(detections)))\n        FP = torch.zeros((len(detections)))\n        total_true_bboxes = len(ground_truths)\n        \n        # Если ничего не существует для этого класса, то можно безопасно пропустить\n        if total_true_bboxes == 0:\n            continue\n\n        for detection_idx, detection in enumerate(detections):\n            # Берем только те истинные рамки, у которых такой же индекс\n            # обучения, как у предсказания\n            ground_truth_img = [\n                bbox for bbox in ground_truths if bbox[0] == detection[0]\n            ]\n\n            num_gts = len(ground_truth_img)\n            best_iou = 0\n\n            for idx, gt in enumerate(ground_truth_img):\n                iou = intersection_over_union(\n                    torch.tensor(detection[3:]),\n                    torch.tensor(gt[3:]),\n                    box_format=box_format,\n                )\n\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt_idx = idx\n\n            if best_iou > iou_threshold:\n                # засчитываем истинное предсказание только один раз\n                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n                    # истинно положительное и добавляем эту рамку в просмотренные\n                    TP[detection_idx] = 1\n                    amount_bboxes[detection[0]][best_gt_idx] = 1\n                else:\n                    FP[detection_idx] = 1\n\n            # если IOU ниже порога, то предсказание является ложноположительным\n            else:\n                FP[detection_idx] = 1\n\n        TP_cumsum = torch.cumsum(TP, dim=0)\n        FP_cumsum = torch.cumsum(FP, dim=0)\n        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n        precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n        precisions = torch.cat((torch.tensor([1]), precisions))\n        recalls = torch.cat((torch.tensor([0]), recalls))\n        # torch.trapz для численного интегрирования\n        average_precisions.append(torch.trapz(precisions, recalls))\n    return sum(average_precisions) / len(average_precisions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:25.788672Z","iopub.execute_input":"2024-12-24T17:57:25.788946Z","iopub.status.idle":"2024-12-24T17:57:25.803141Z","shell.execute_reply.started":"2024-12-24T17:57:25.788916Z","shell.execute_reply":"2024-12-24T17:57:25.802431Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def get_bboxes(\n    loader,\n    model,\n    iou_threshold,\n    threshold,\n    pred_format=\"cells\",\n    box_format=\"midpoint\",\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n):\n    all_pred_boxes = []\n    all_true_boxes = []\n\n    # make sure model is in eval before get bboxes\n    model.eval()\n    train_idx = 0\n\n    for batch_idx, (x, labels) in enumerate(loader):\n        x = x.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            predictions = model(x)\n\n        batch_size = x.shape[0]\n        true_bboxes = cellboxes_to_boxes(labels)\n        bboxes = cellboxes_to_boxes(predictions)\n\n        for idx in range(batch_size):\n            nms_boxes = non_max_suppression(\n                bboxes[idx],\n                iou_threshold=iou_threshold,\n                threshold=threshold,\n                box_format=box_format,\n            )\n\n            for nms_box in nms_boxes:\n                all_pred_boxes.append([train_idx] + nms_box)\n\n            for box in true_bboxes[idx]:\n                # many will get converted to 0 pred\n                if box[1] > threshold:\n                    all_true_boxes.append([train_idx] + box)\n\n            train_idx += 1\n\n    model.train()\n    return all_pred_boxes, all_true_boxes\n\n\n\ndef convert_cellboxes(predictions, S=7, C=7):\n    \"\"\"\n    Преобразует ограничивающие рамки, полученные от Yolo с\n    размером разбиения изображения S, в соотношения для всего изображения,\n    а не относительно ячеек. Пытались сделать это векторизованно,\n    но это привело к довольно сложному для чтения коду...\n    Использовать как черный ящик? Или реализовать более интуитивно понятный метод,\n    используя 2 цикла for, которые перебирают range(S) и преобразуют их\n    по одному, что приведет к более медленной, но более читаемой реализации.\n    \"\"\"\n\n    predictions = predictions.to(\"cpu\")\n    batch_size = predictions.shape[0]\n    predictions = predictions.reshape(batch_size, S, S, C + 10)\n    bboxes1 = predictions[..., C + 1:C + 5]\n    bboxes2 = predictions[..., C + 6:C + 10]\n    scores = torch.cat(\n        (predictions[..., C].unsqueeze(0), predictions[..., C + 5].unsqueeze(0)), dim=0\n    )\n    best_box = scores.argmax(0).unsqueeze(-1)\n    best_boxes = bboxes1 * (1 - best_box) + best_box * bboxes2\n    cell_indices = torch.arange(7).repeat(batch_size, 7, 1).unsqueeze(-1)\n    x = 1 / S * (best_boxes[..., :1] + cell_indices)\n    y = 1 / S * (best_boxes[..., 1:2] + cell_indices.permute(0, 2, 1, 3))\n    w_y = 1 / S * best_boxes[..., 2:4]\n    converted_bboxes = torch.cat((x, y, w_y), dim=-1)\n    predicted_class = predictions[..., :C].argmax(-1).unsqueeze(-1)\n    best_confidence = torch.max(predictions[..., C], predictions[..., C + 5]).unsqueeze(\n        -1\n    )\n    converted_preds = torch.cat(\n        (predicted_class, best_confidence, converted_bboxes), dim=-1\n    )\n\n    return converted_preds\n\n\ndef cellboxes_to_boxes(out, S=7):\n    converted_pred = convert_cellboxes(out).reshape(out.shape[0], S * S, -1)\n    converted_pred[..., 0] = converted_pred[..., 0].long()\n    all_bboxes = []\n\n    for ex_idx in range(out.shape[0]):\n        bboxes = []\n\n        for bbox_idx in range(S * S):\n            bboxes.append([x.item() for x in converted_pred[ex_idx, bbox_idx, :]])\n        all_bboxes.append(bboxes)\n\n    return all_bboxes\n\ndef save_checkpoint(state, filename=\"my_checkpoint.pth\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n    \ndef load_checkpoint(checkpoint, model, optimizer):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:25.804103Z","iopub.execute_input":"2024-12-24T17:57:25.804489Z","iopub.status.idle":"2024-12-24T17:57:25.820367Z","shell.execute_reply.started":"2024-12-24T17:57:25.804463Z","shell.execute_reply":"2024-12-24T17:57:25.819648Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"class BTSDataset(torch.utils.data.Dataset):\n    def __init__(self, df=df, files_dir=files_dir, S=7, B=2, C=7, transform=None):\n        self.annotations = df\n        self.files_dir = files_dir\n        self.transform = transform\n        self.S = S\n        self.B = B\n        self.C = C\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        label_path = os.path.join(self.files_dir, self.annotations.iloc[index, 1])\n        boxes = []\n        names = sorted(['jhope', 'jimin', 'jin', 'suga', 'jungkook', 'rm', 'v'])\n        class_dictionary = dict((i, names[i]) for i in range(7))\n        with open(label_path,'r') as file:\n            klass, centerx, centery, boxwidth, boxheight = map(float, file.readline()[:-1].split())\n            boxes.append([klass, centerx, centery, boxwidth, boxheight])\n                \n        boxes = torch.tensor(boxes)\n        img_path = os.path.join(self.files_dir, self.annotations.iloc[index, 0])\n        image = Image.open(img_path)\n        image = image.convert(\"RGB\")\n\n        if self.transform:\n            # image = self.transform(image)\n            image, boxes = self.transform(image, boxes)\n\n        # Convert To Cells\n        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n        for box in boxes:\n            class_label, x, y, width, height = box.tolist()\n            class_label = int(class_label)\n\n            # i,j represents the cell row and cell column\n            i, j = int(self.S * y), int(self.S * x)\n            x_cell, y_cell = self.S * x - j, self.S * y - i\n\n            \"\"\"\n            Вычисление ширины и высоты ячейки ограничивающей рамки\n            относительно ячейки выполняется следующим образом, на примере\n            ширины:\n            \n            width_pixels = (width*self.image_width)\n            cell_pixels = (self.image_width)\n            \n            Затем, чтобы найти ширину относительно ячейки, достаточно:\n            width_pixels/cell_pixels, что при упрощении приводит к\n            формулам ниже.\n            \"\"\"\n            width_cell, height_cell = (\n                width * self.S,\n                height * self.S,\n            )\n\n            # If no object already found for specific cell i,j\n            # Note: This means we restrict to ONE object\n            # per cell!\n#             print(i, j)\n            if label_matrix[i, j, self.C] == 0:\n                # Set that there exists an object\n                label_matrix[i, j, self.C] = 1\n\n                # Box coordinates\n                box_coordinates = torch.tensor(\n                    [x_cell, y_cell, width_cell, height_cell]\n                )\n\n                label_matrix[i, j, 4:8] = box_coordinates\n\n                # Set one hot encoding for class_label\n                label_matrix[i, j, class_label] = 1\n\n        return image, label_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:26.998188Z","iopub.execute_input":"2024-12-24T17:57:26.998526Z","iopub.status.idle":"2024-12-24T17:57:27.015278Z","shell.execute_reply.started":"2024-12-24T17:57:26.998491Z","shell.execute_reply":"2024-12-24T17:57:27.014430Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"class YoloLoss(nn.Module):\n    \"\"\"\n    Calculate the loss for yolo (v1) model\n    \"\"\"\n\n    def __init__(self, S=7, B=2, C=7):\n        super(YoloLoss, self).__init__()\n        self.mse = nn.MSELoss(reduction=\"sum\")\n\n        \"\"\"\n        S is split size of image (in paper 7),\n        B is number of boxes (in paper 2),\n        C is number of classes (in paper 20, in dataset 3),\n        \"\"\"\n        self.S = S\n        self.B = B\n        self.C = C\n\n        # These are from Yolo paper, signifying how much we should\n        # pay loss for no object (noobj) and the box coordinates (coord)\n        self.lambda_noobj = 0.5\n        self.lambda_coord = 5\n\n    def forward(self, predictions, target):\n        # predictions are shaped (BATCH_SIZE, S*S(C+B*5) when inputted\n        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n\n        # Calculate IoU for the two predicted bounding boxes with target bbox\n        iou_b1 = intersection_over_union(predictions[..., self.C + 1:self.C + 5], target[..., self.C + 1:self.C + 5])\n        iou_b2 = intersection_over_union(predictions[..., self.C + 6:self.C + 10], target[..., self.C + 1:self.C + 5])\n        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n\n        # Take the box with highest IoU out of the two prediction\n        # Note that bestbox will be indices of 0, 1 for which bbox was best\n        iou_maxes, bestbox = torch.max(ious, dim=0)\n        exists_box = target[..., self.C].unsqueeze(3)  # in paper this is Iobj_i\n\n        # ======================== #\n        #   FOR BOX COORDINATES    #\n        # ======================== #\n\n        # Set boxes with no object in them to 0. We only take out one of the two \n        # predictions, which is the one with highest Iou calculated previously.\n        box_predictions = exists_box * (\n            (\n                bestbox * predictions[..., self.C + 6:self.C + 10]\n                + (1 - bestbox) * predictions[..., self.C + 1:self.C + 5]\n            )\n        )\n\n        box_targets = exists_box * target[..., self.C + 1:self.C + 5]\n\n        # Take sqrt of width, height of boxes to ensure that\n        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n            torch.abs(box_predictions[..., 2:4] + 1e-6)\n        )\n        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n\n        box_loss = self.mse(\n            torch.flatten(box_predictions, end_dim=-2),\n            torch.flatten(box_targets, end_dim=-2),\n        )\n\n        # ==================== #\n        #   FOR OBJECT LOSS    #\n        # ==================== #\n\n        # pred_box is the confidence score for the bbox with highest IoU\n        pred_box = (\n            bestbox * predictions[..., self.C + 5:self.C + 6] + (1 - bestbox) * predictions[..., self.C:self.C + 1]\n        )\n\n        object_loss = self.mse(\n            torch.flatten(exists_box * pred_box),\n            torch.flatten(exists_box * target[..., self.C:self.C + 1]),\n        )\n\n        # ======================= #\n        # ЛОСС ОТСУТСТВИЯ КЛАССА  #\n        # ======================= #\n\n        no_object_loss = self.mse(\n            torch.flatten((1 - exists_box) * predictions[..., self.C:self.C + 1], start_dim=1),\n            torch.flatten((1 - exists_box) * target[..., self.C:self.C + 1], start_dim=1),\n        )\n\n        no_object_loss += self.mse(\n            torch.flatten((1 - exists_box) * predictions[..., self.C + 5:self.C + 6], start_dim=1),\n            torch.flatten((1 - exists_box) * target[..., self.C:self.C + 1], start_dim=1)\n        )\n\n        # ================== #\n        #   КЛАССОВЫЙ ЛОСС   #\n        # ================== #\n\n        class_loss = self.mse(\n            torch.flatten(exists_box * predictions[..., :self.C], end_dim=-2,),\n            torch.flatten(exists_box * target[..., :self.C], end_dim=-2,),\n        )\n\n        loss = (\n            self.lambda_coord * box_loss  # first two rows in paper\n            + object_loss  # third row in paper\n            + self.lambda_noobj * no_object_loss  # forth row\n            + class_loss  # fifth row\n        )\n\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:27.016536Z","iopub.execute_input":"2024-12-24T17:57:27.016858Z","iopub.status.idle":"2024-12-24T17:57:27.032885Z","shell.execute_reply.started":"2024-12-24T17:57:27.016823Z","shell.execute_reply":"2024-12-24T17:57:27.032051Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"LEARNING_RATE = 1e-3\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 32 # 64 in original paper but resource exhausted error otherwise.\nWEIGHT_DECAY = 0.1\nEPOCHS = 20\nNUM_WORKERS = 2\nPIN_MEMORY = True\nLOAD_MODEL = False\nLOAD_MODEL_FILE = \"model.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:27.033854Z","iopub.execute_input":"2024-12-24T17:57:27.034100Z","iopub.status.idle":"2024-12-24T17:57:27.048520Z","shell.execute_reply.started":"2024-12-24T17:57:27.034077Z","shell.execute_reply":"2024-12-24T17:57:27.047755Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def train_fn(train_loader, model, optimizer, loss_fn):\n    loop = tqdm(train_loader, leave=True)\n    mean_loss = []\n    \n    for batch_idx, (x, y) in enumerate(loop):\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        out = model(x)\n        loss = loss_fn(out, y)\n        mean_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loop.set_postfix(loss = loss.item())\n        \n    print(f\"Mean loss was {sum(mean_loss) / len(mean_loss)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:27.049546Z","iopub.execute_input":"2024-12-24T17:57:27.049885Z","iopub.status.idle":"2024-12-24T17:57:27.064443Z","shell.execute_reply.started":"2024-12-24T17:57:27.049850Z","shell.execute_reply":"2024-12-24T17:57:27.063636Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"class Compose(object):\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img, bboxes):\n        for t in self.transforms:\n            img, bboxes = t(img), bboxes\n\n        return img, bboxes\n\n\ntransform = Compose([transforms.Resize((448, 448)), transforms.ToTensor()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:27.065334Z","iopub.execute_input":"2024-12-24T17:57:27.065627Z","iopub.status.idle":"2024-12-24T17:57:27.076324Z","shell.execute_reply.started":"2024-12-24T17:57:27.065603Z","shell.execute_reply":"2024-12-24T17:57:27.075431Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"def main():\n    model = YoloV1(split_size=7, num_boxes=2, num_classes=7).to(DEVICE)\n    optimizer = optim.Adam(\n        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n    )\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=3, mode='max', verbose=True)\n    loss_fn = YoloLoss()\n\n    if LOAD_MODEL:\n        load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n\n    train_dataset = BTSDataset(\n        transform=transform,\n        files_dir=files_dir,\n        df = train\n    )\n\n    test_dataset = BTSDataset(\n        transform=transform, \n        files_dir=files_dir,\n        df = test\n    )\n\n    train_loader = DataLoader(\n        dataset=train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        drop_last=False,\n    )\n\n    test_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        drop_last=False,\n    )\n\n    for epoch in range(EPOCHS):\n        train_fn(train_loader, model, optimizer, loss_fn)\n        \n        pred_boxes, target_boxes = get_bboxes(\n            train_loader, model, iou_threshold=0.9, threshold=0.9\n        )\n\n        mean_avg_prec = mean_average_precision(\n            pred_boxes, target_boxes, iou_threshold=0.2, box_format=\"midpoint\"\n        )\n        print(f\"Train mAP: {mean_avg_prec}\")\n        \n        scheduler.step(mean_avg_prec)\n    \n    checkpoint = {\n            \"state_dict\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n    }\n    save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:27.077397Z","iopub.execute_input":"2024-12-24T17:57:27.077802Z","iopub.status.idle":"2024-12-24T17:57:27.090552Z","shell.execute_reply.started":"2024-12-24T17:57:27.077764Z","shell.execute_reply":"2024-12-24T17:57:27.089751Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:27.091624Z","iopub.execute_input":"2024-12-24T17:57:27.091973Z","iopub.status.idle":"2024-12-24T17:57:28.448646Z","shell.execute_reply.started":"2024-12-24T17:57:27.091937Z","shell.execute_reply":"2024-12-24T17:57:28.447278Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n  0%|          | 0/21 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[47], line 39\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     32\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[1;32m     33\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     34\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     pred_boxes, target_boxes \u001b[38;5;241m=\u001b[39m get_bboxes(\n\u001b[1;32m     42\u001b[0m         train_loader, model, iou_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     mean_avg_prec \u001b[38;5;241m=\u001b[39m mean_average_precision(\n\u001b[1;32m     46\u001b[0m         pred_boxes, target_boxes, iou_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, box_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m     )\n","Cell \u001b[0;32mIn[45], line 7\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loop):\n\u001b[1;32m      6\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(DEVICE), y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 7\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(out, y)\n\u001b[1;32m      9\u001b[0m     mean_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[32], line 11\u001b[0m, in \u001b[0;36mYoloV1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdarknet(x)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x1000 and 100352x496)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x1000 and 100352x496)","output_type":"error"}],"execution_count":48},{"cell_type":"code","source":"LOAD_MODEL = True\nEPOCHS = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.449730Z","iopub.status.idle":"2024-12-24T17:57:28.450178Z","shell.execute_reply.started":"2024-12-24T17:57:28.449949Z","shell.execute_reply":"2024-12-24T17:57:28.449972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predictions():\n    model = YoloV1(split_size=7, num_boxes=2, num_classes=7).to(DEVICE)\n    optimizer = optim.Adam(\n        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n    )\n    loss_fn = YoloLoss()\n\n    if LOAD_MODEL:\n        load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n\n    test_dataset = BTSDataset(\n        transform=transform, \n        df=test,\n        files_dir=files_dir\n    )\n\n    test_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        drop_last=False,\n    )\n        \n    for epoch in range(EPOCHS):\n        model.eval()\n        train_fn(test_loader, model, optimizer, loss_fn)\n        \n        pred_boxes, target_boxes = get_bboxes(\n            test_loader, model, iou_threshold=0.9, threshold=0.9\n        )\n\n        mean_avg_prec = mean_average_precision(\n            pred_boxes, target_boxes, iou_threshold=0.9, box_format=\"midpoint\"\n        )\n        print(f\"Test mAP: {mean_avg_prec}\")\n\n\npredictions()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.451137Z","iopub.status.idle":"2024-12-24T17:57:28.451590Z","shell.execute_reply.started":"2024-12-24T17:57:28.451342Z","shell.execute_reply":"2024-12-24T17:57:28.451364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YoloV1(split_size=7, num_boxes=2, num_classes=7).to(DEVICE)\n\noptimizer = optim.Adam(\n        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n)\n\nloss_fn = YoloLoss()\n\nload_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n\ntest_dataset = BTSDataset(\n        transform=transform, \n        df=test,\n        files_dir=files_dir\n    )\n\ntest_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        drop_last=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.453416Z","iopub.status.idle":"2024-12-24T17:57:28.453857Z","shell.execute_reply.started":"2024-12-24T17:57:28.453633Z","shell.execute_reply":"2024-12-24T17:57:28.453655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_bboxes_images(\n    loader,\n    model,\n    iou_threshold,\n    threshold,\n    pred_format=\"cells\",\n    box_format=\"midpoint\",\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n):\n    all_pred_boxes = []\n    all_true_boxes = []\n\n    # make sure model is in eval before get bboxes\n    model.eval()\n    train_idx = 0\n    all_images = []\n    for batch_idx, (x, labels) in enumerate(loader):\n        all_images.append(x)\n        x = x.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            predictions = model(x)\n\n        batch_size = x.shape[0]\n        true_bboxes = cellboxes_to_boxes(labels)\n        bboxes = cellboxes_to_boxes(predictions)\n\n        for idx in range(batch_size):\n            nms_boxes = non_max_suppression(\n                bboxes[idx],\n                iou_threshold=iou_threshold,\n                threshold=threshold,\n                box_format=box_format,\n            )\n\n\n            #if batch_idx == 0 and idx == 0:\n            #    plot_image(x[idx].permute(1,2,0).to(\"cpu\"), nms_boxes)\n            #    print(nms_boxes)\n\n            for nms_box in nms_boxes:\n                all_pred_boxes.append([train_idx] + nms_box)\n\n            for box in true_bboxes[idx]:\n                # many will get converted to 0 pred\n                if box[1] > threshold:\n                    all_true_boxes.append([train_idx] + box)\n\n            train_idx += 1\n\n    model.train()\n    return all_pred_boxes, all_true_boxes, torch.cat(all_images, dim=0)\n\n\npred_boxes, target_boxes, images = get_bboxes_images(\n            test_loader, model, iou_threshold=0.9, threshold=0.9\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.454893Z","iopub.status.idle":"2024-12-24T17:57:28.455357Z","shell.execute_reply.started":"2024-12-24T17:57:28.455116Z","shell.execute_reply":"2024-12-24T17:57:28.455141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = [{'num_imag': pred_box[0], 'class': pred_box[1], 'conf': pred_box[2], 'box': list(np.array(pred_box[3:])*448)} \\\n         for pred_box in pred_boxes]\npreds[:10:1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.457007Z","iopub.status.idle":"2024-12-24T17:57:28.457453Z","shell.execute_reply.started":"2024-12-24T17:57:28.457211Z","shell.execute_reply":"2024-12-24T17:57:28.457234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.459055Z","iopub.status.idle":"2024-12-24T17:57:28.459514Z","shell.execute_reply.started":"2024-12-24T17:57:28.459260Z","shell.execute_reply":"2024-12-24T17:57:28.459283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncolor_classes = {\n    0:'red',\n    1:\"blue\",\n    2:\"green\",\n    3:'purple',\n    4:'orange',\n    5:'yellow',\n    6:'black'\n}\n\nfig, ax = plt.subplots(5, 5, figsize = (10, 10))\nfor idx, image in enumerate(images):\n    try:\n        ax[idx//5, idx%5].imshow(image.permute((1, 2, 0)).detach().numpy())\n    except IndexError:\n        pass\nfor box in preds:\n    # Create a Rectangle patch\n    box_rect = box.get('box')\n    center_x = box_rect[0]\n    center_y = box_rect[1]\n    width = box_rect[2]\n    height = box_rect[3]\n    rect = patches.Rectangle((center_x, center_y), \n                             width, height, \n                             linewidth=1, \n                             edgecolor=color_classes.get(int(box.get(\"class\"))), \n                             facecolor='none')\n    idx_box = box.get(\"num_imag\")\n    # Add the patch to the Axes\n    try:\n        ax[idx_box//5, idx_box%5].add_patch(rect)\n    except IndexError:\n        pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T17:57:28.461431Z","iopub.status.idle":"2024-12-24T17:57:28.462316Z","shell.execute_reply.started":"2024-12-24T17:57:28.462074Z","shell.execute_reply":"2024-12-24T17:57:28.462099Z"}},"outputs":[],"execution_count":null}]}